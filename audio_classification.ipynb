{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10800/10800 [00:39<00:00, 273.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed data to processed_data.npz\n"
     ]
    }
   ],
   "source": [
    "audio_dir = \"/Users/manidatta/Documents/Neural Nets and Deep Learning/Project/fsd50k/FSD50K.dev_audio_16k/\"\n",
    "output_path = \"processed_data.npz\"\n",
    "\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "N_MELS = 128\n",
    "SPEC_SHAPE = (128, 128)\n",
    "duration = 5\n",
    "\n",
    "df = pd.read_csv(\"FSD50K_Data.csv\")\n",
    "\n",
    "risk_encoder = LabelEncoder()\n",
    "df['risklevel_encoded'] = risk_encoder.fit_transform(df['risk_level'])\n",
    "\n",
    "location_encoder = LabelEncoder()\n",
    "df['location_encoded'] = location_encoder.fit_transform(df['location'])\n",
    "\n",
    "\n",
    "X = []\n",
    "locations = []\n",
    "y = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    file_path = os.path.join(audio_dir, f\"{row['fname']}.wav\")\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "\n",
    "    audio, sr = librosa.load(file_path, sr=SAMPLE_RATE,duration=duration)\n",
    "\n",
    "    if len(audio) < sr * duration:\n",
    "        audio = np.pad(audio, (0,sr*duration - len(audio)))\n",
    "        \n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=N_MELS)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    mel_db = librosa.util.fix_length(mel_db, size=216, axis=1)\n",
    "\n",
    "    mel_db = (mel_db - mel_db.mean()) / (mel_db.std() + 1e-9) # Normalize\n",
    "\n",
    "    X.append(mel_db)\n",
    "    y.append(row['risklevel_encoded'])\n",
    "    locations.append(row[\"location_encoded\"])\n",
    "\n",
    "\n",
    "X = np.array(X).astype(np.float32)\n",
    "y = np.array(y)\n",
    "locations = np.array(locations)\n",
    "\n",
    "# Save\n",
    "np.savez(output_path, X=X, y=y, locations=locations, risklevel_classes = risk_encoder.classes_, location_classes = location_encoder.classes_)\n",
    "\n",
    "print(f\"Saved preprocessed data to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50Data(Dataset):\n",
    "    def __init__(self,data_path):\n",
    "        data = np.load(data_path,allow_pickle=True)\n",
    "        self.X_audio = data['X']\n",
    "        self.location = data['locations']\n",
    "        self.y = data['y']\n",
    "        self.location_classes = data['location_classes']\n",
    "        self.risklevel_classes = data['risklevel_classes']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_audio)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.X_audio[index]\n",
    "        y = self.y[index]\n",
    "        location = self.location[index]\n",
    "        # converting the spectogram into float tensor with shape(channel dimension,128,128)\n",
    "        # usually spectograms has 1 channel like gray scale images\n",
    "        x = torch.tensor(x).unsqueeze(0).float()\n",
    "        # converting the encoded locations into tensor\n",
    "        locations = torch.tensor(location).long()\n",
    "        # converting the encoded labels into long tensor\n",
    "        y = torch.tensor(y).long()\n",
    "\n",
    "        return x,y, locations\n",
    "    \n",
    "# Loading the dataset\n",
    "data = ESC50Data(\"/Users/manidatta/Documents/Neural Nets and Deep Learning/Project/processed_data.npz\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generating the suffled indices\n",
    "indices = np.random.permutation(len(data))\n",
    "# splitting the data into train,val and test \n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_idx = indices[:train_size]\n",
    "val_idx = indices[train_size:train_size + val_size]\n",
    "test_idx = indices[train_size + val_size:]\n",
    "\n",
    "train_set = Subset(data, train_idx)\n",
    "val_set = Subset(data, val_idx)\n",
    "test_set = Subset(data, test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RiskLevelClassifier(nn.Module):\n",
    "    def __init__(self, n_locations,n_mels =128, spec_len=216,n_classes=3,hidden_dim=128, n_heads = 4, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Each incoming spectogram has the dimension spec_len x n_mels\n",
    "        # diving the spectogram into 16 x 16 batches and passing the resulted tokens as the sequence to the encoder\n",
    "\n",
    "        self.patch_embedded = nn.Conv2d(1,hidden_dim, kernel_size=(16,16),stride=(16,16))\n",
    "        num_patches = (n_mels // 16) * (spec_len // 16)\n",
    "\n",
    "        self.postional_embedding = nn.Parameter(torch.randn(1,num_patches,hidden_dim))\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_dim,nhead=n_heads,dim_feedforward=hidden_dim*2, batch_first=True),\n",
    "            num_layers=n_layers\n",
    "        )\n",
    "\n",
    "        self.location_embeddding = nn.Embedding(n_locations,hidden_dim)\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim,n_classes)\n",
    "        )\n",
    "\n",
    "    # feed forward network\n",
    "    def forward(self, x, loc):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        patches = self.patch_embedded(x) # [batch_size, hidden_size,H,W] H and W are the number of patches along x and y \n",
    "\n",
    "        patches = patches.flatten(2).transpose(1,2) # flattening the last two dimensions gives the number of total patches\n",
    "\n",
    "        # adding the positional encoding in order for the encoder to identify the patch\n",
    "        patches = patches + self.postional_embedding\n",
    "\n",
    "        # passing the patches to the encoder\n",
    "        audio = self.transformer_encoder(patches)\n",
    "\n",
    "        # taking average across the patches \n",
    "        audio = audio.mean(dim=1)\n",
    "\n",
    "        # adding the embedding to the locations\n",
    "        location = self.location_embeddding(loc)\n",
    "\n",
    "        # fusioning of both audio features and locations\n",
    "        fusion = torch.cat([audio,location],dim=1)\n",
    "\n",
    "        output = self.classifier(fusion)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MSDSNP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-24 21:23:16,931] A new study created in memory with name: no-name-3a6ba43c-ce56-47ff-a322-cc67aab15a72\n",
      "/var/folders/_h/ngxdgxln57gb923874j8w4rh0000gn/T/ipykernel_18864/1167971833.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\",1e-3, 5e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trail 0 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0023796694633943785,hidden dimension=256, optimizer=Adam, heads=4,batch size=32\n",
      "Epoch [1/5] - Train Loss: 0.3599,train Acc: 0.8414, Val Loss: 0.2884, Val Acc: 0.8630\n",
      "Epoch [2/5] - Train Loss: 0.3295,train Acc: 0.8481, Val Loss: 0.3161, Val Acc: 0.8657\n",
      "Epoch [3/5] - Train Loss: 0.3207,train Acc: 0.8512, Val Loss: 0.2824, Val Acc: 0.8722\n",
      "Epoch [4/5] - Train Loss: 0.3119,train Acc: 0.8501, Val Loss: 0.2830, Val Acc: 0.8657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:25:26,919] Trial 0 finished with value: 0.8722222222222222 and parameters: {'learning_rate': 0.0023796694633943785, 'hidden_dimension': 256, 'n_heads': 4, 'batch_size': 32, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.8722222222222222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Train Loss: 0.3101,train Acc: 0.8554, Val Loss: 0.2830, Val Acc: 0.8602\n",
      "Trial 0 Completed!  Val Acc: 0.8722\n",
      "\n",
      "Running Trail 1 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.004142081295742737,hidden dimension=128, optimizer=Adam, heads=8,batch size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/ngxdgxln57gb923874j8w4rh0000gn/T/ipykernel_18864/1167971833.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\",1e-3, 5e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Train Loss: 0.3634,train Acc: 0.8407, Val Loss: 0.2972, Val Acc: 0.8657\n",
      "Epoch [2/5] - Train Loss: 0.3165,train Acc: 0.8537, Val Loss: 0.3007, Val Acc: 0.8454\n",
      "Epoch [3/5] - Train Loss: 0.3212,train Acc: 0.8501, Val Loss: 0.2859, Val Acc: 0.8676\n",
      "Epoch [4/5] - Train Loss: 0.3116,train Acc: 0.8500, Val Loss: 0.2807, Val Acc: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:26:42,490] Trial 1 finished with value: 0.8675925925925926 and parameters: {'learning_rate': 0.004142081295742737, 'hidden_dimension': 128, 'n_heads': 8, 'batch_size': 32, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.8722222222222222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Train Loss: 0.3084,train Acc: 0.8543, Val Loss: 0.2728, Val Acc: 0.8676\n",
      "Trial 1 Completed!  Val Acc: 0.8676\n",
      "\n",
      "Running Trail 2 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0015836849234370496,hidden dimension=512, optimizer=SGD, heads=4,batch size=64\n",
      "Epoch [1/5] - Train Loss: 0.5445,train Acc: 0.8049, Val Loss: 0.3473, Val Acc: 0.8620\n",
      "Epoch [2/5] - Train Loss: 0.3431,train Acc: 0.8507, Val Loss: 0.3065, Val Acc: 0.8426\n",
      "Epoch [3/5] - Train Loss: 0.3220,train Acc: 0.8512, Val Loss: 0.2882, Val Acc: 0.8731\n",
      "Epoch [4/5] - Train Loss: 0.3171,train Acc: 0.8542, Val Loss: 0.2910, Val Acc: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:31:27,204] Trial 2 finished with value: 0.8731481481481481 and parameters: {'learning_rate': 0.0015836849234370496, 'hidden_dimension': 512, 'n_heads': 4, 'batch_size': 64, 'optimizer': 'SGD'}. Best is trial 2 with value: 0.8731481481481481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Train Loss: 0.3121,train Acc: 0.8519, Val Loss: 0.2816, Val Acc: 0.8620\n",
      "Trial 2 Completed!  Val Acc: 0.8731\n",
      "\n",
      "Running Trail 3 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0032717950490971375,hidden dimension=128, optimizer=Adam, heads=4,batch size=32\n",
      "Epoch [1/5] - Train Loss: 0.3719,train Acc: 0.8394, Val Loss: 0.2903, Val Acc: 0.8676\n",
      "Epoch [2/5] - Train Loss: 0.3171,train Acc: 0.8538, Val Loss: 0.2963, Val Acc: 0.8667\n",
      "Epoch [3/5] - Train Loss: 0.3080,train Acc: 0.8562, Val Loss: 0.2753, Val Acc: 0.8648\n",
      "Epoch [4/5] - Train Loss: 0.3063,train Acc: 0.8556, Val Loss: 0.2760, Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:32:33,831] Trial 3 finished with value: 0.8740740740740741 and parameters: {'learning_rate': 0.0032717950490971375, 'hidden_dimension': 128, 'n_heads': 4, 'batch_size': 32, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.8740740740740741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Train Loss: 0.3048,train Acc: 0.8575, Val Loss: 0.2814, Val Acc: 0.8722\n",
      "Trial 3 Completed!  Val Acc: 0.8741\n",
      "\n",
      "Running Trail 4 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0021149315292142185,hidden dimension=512, optimizer=SGD, heads=8,batch size=32\n",
      "Epoch [1/5] - Train Loss: 0.4193,train Acc: 0.8331, Val Loss: 0.3077, Val Acc: 0.8676\n",
      "Epoch [2/5] - Train Loss: 0.3196,train Acc: 0.8493, Val Loss: 0.2841, Val Acc: 0.8630\n",
      "Epoch [3/5] - Train Loss: 0.3137,train Acc: 0.8528, Val Loss: 0.2771, Val Acc: 0.8657\n",
      "Epoch [4/5] - Train Loss: 0.3093,train Acc: 0.8532, Val Loss: 0.2786, Val Acc: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:37:08,959] Trial 4 finished with value: 0.8703703703703703 and parameters: {'learning_rate': 0.0021149315292142185, 'hidden_dimension': 512, 'n_heads': 8, 'batch_size': 32, 'optimizer': 'SGD'}. Best is trial 3 with value: 0.8740740740740741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Train Loss: 0.3025,train Acc: 0.8545, Val Loss: 0.2738, Val Acc: 0.8704\n",
      "Trial 4 Completed!  Val Acc: 0.8704\n",
      "\n",
      "Running Trail 5 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0021822709586366627,hidden dimension=256, optimizer=SGD, heads=4,batch size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:37:35,023] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Train Loss: 0.4733,train Acc: 0.8208, Val Loss: 0.3338, Val Acc: 0.8583\n",
      "Running Trail 6 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0015889094334850258,hidden dimension=256, optimizer=AdamW, heads=8,batch size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:38:01,147] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Train Loss: 0.3605,train Acc: 0.8449, Val Loss: 0.2941, Val Acc: 0.8611\n",
      "Running Trail 7 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0018783542446182497,hidden dimension=128, optimizer=AdamW, heads=8,batch size=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:38:16,001] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Train Loss: 0.3913,train Acc: 0.8341, Val Loss: 0.2893, Val Acc: 0.8574\n",
      "Running Trail 8 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.004805201212798715,hidden dimension=256, optimizer=Adam, heads=4,batch size=64\n",
      "Epoch [1/5] - Train Loss: 0.3867,train Acc: 0.8309, Val Loss: 0.2869, Val Acc: 0.8722\n",
      "Epoch [2/5] - Train Loss: 0.3263,train Acc: 0.8507, Val Loss: 0.2805, Val Acc: 0.8704\n",
      "Epoch [3/5] - Train Loss: 0.3174,train Acc: 0.8495, Val Loss: 0.2871, Val Acc: 0.8519\n",
      "Epoch [4/5] - Train Loss: 0.3120,train Acc: 0.8532, Val Loss: 0.2746, Val Acc: 0.8694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:40:24,906] Trial 8 finished with value: 0.8722222222222222 and parameters: {'learning_rate': 0.004805201212798715, 'hidden_dimension': 256, 'n_heads': 4, 'batch_size': 64, 'optimizer': 'Adam'}. Best is trial 3 with value: 0.8740740740740741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] - Train Loss: 0.3125,train Acc: 0.8558, Val Loss: 0.2806, Val Acc: 0.8574\n",
      "Trial 8 Completed!  Val Acc: 0.8722\n",
      "\n",
      "Running Trail 9 \n",
      "\n",
      "Selected Hyperparameters: learning rate=0.0020023276319776724,hidden dimension=512, optimizer=AdamW, heads=4,batch size=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 21:41:19,946] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Train Loss: 0.3734,train Acc: 0.8354, Val Loss: 0.3124, Val Acc: 0.8648\n",
      "Best Hyperparameters: {'learning_rate': 0.0032717950490971375, 'hidden_dimension': 128, 'n_heads': 4, 'batch_size': 32, 'optimizer': 'Adam'}\n",
      "Best model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Trained the model and performing the hyperparameter tuning using validation data\n",
    "import optuna\n",
    "import torch.optim as optim\n",
    "# Initializing the  Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "global_best_model_state = None\n",
    "global_best_accuracy = 0  \n",
    "\n",
    "def optimization(trial):\n",
    "    global global_best_model_state, global_best_accuracy \n",
    "    print(f\"Running Trail {trial.number} \\n\")\n",
    "    # defining different hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\",1e-3, 5e-3)\n",
    "    hidden_dimension= trial.suggest_categorical(\"hidden_dimension\",[128,256,512])\n",
    "    n_heads = trial.suggest_categorical(\"n_heads\",[4,8])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\",[32,64])\n",
    "    optimizers = trial.suggest_categorical(\"optimizer\",[\"Adam\",\"SGD\",\"AdamW\"])\n",
    "    \n",
    "    print(f\"Selected Hyperparameters: learning rate={learning_rate},hidden dimension={hidden_dimension}, optimizer={optimizers}, heads={n_heads},batch size={batch_size}\")\n",
    "\n",
    "    # Device config\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    n_locations = len(location_encoder.classes_)\n",
    "    \n",
    "    # defining the model\n",
    "    model = RiskLevelClassifier(hidden_dim=hidden_dimension,n_locations=n_locations).to(device)\n",
    "\n",
    "    # Loss \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # initializing the selected optimizer\n",
    "    if optimizers ==\"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-4)\n",
    "    elif optimizers ==\"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9)\n",
    "    elif optimizers ==\"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(),lr=learning_rate,weight_decay=1e-4)\n",
    "    \n",
    "    # loading data for different batch sizes\n",
    "    train_data = DataLoader(train_set,batch_size=batch_size, shuffle=True)\n",
    "    val_data = DataLoader(val_set,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    best_validation_accuracy = 0\n",
    "    best_model_state = None\n",
    "    # Training for five epochs\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "    \n",
    "        for spectrograms, labels, locations in train_data:\n",
    "            spectrograms = spectrograms.to(device)\n",
    "            locations = locations.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(spectrograms, locations)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * spectrograms.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss =0\n",
    "        val_correct, val_total = 0,0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for spectrograms, labels, locations in val_data:\n",
    "                spectrograms = spectrograms.to(device)\n",
    "                locations = locations.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(spectrograms, locations)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * spectrograms.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # calculating the training and validation loss per each batch \n",
    "        average_train_loss = train_loss / train_total\n",
    "        average_val_loss = val_loss / val_total\n",
    "\n",
    "        # calculating the validation accuracy and train accuracy\n",
    "        validation_accuracy = val_correct/val_total\n",
    "        train_accuracy = train_correct/ train_total\n",
    "        print(f\"Epoch [{epoch+1}/{5}] - Train Loss: {average_train_loss:.4f},train Acc: {train_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Acc: {validation_accuracy:.4f}\")\n",
    "\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        # Early Stopping if Validation accuracy is Not Improving\n",
    "        # reporting the loss for pruning\n",
    "        trial.report(validation_accuracy,epoch)\n",
    "\n",
    "        # Stopping the epoch loop early if the validation is not improving much\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    print(f\"Trial {trial.number} Completed!  Val Acc: {best_validation_accuracy:.4f}\\n\")\n",
    "    if best_validation_accuracy > global_best_accuracy:\n",
    "        global_best_accuracy = best_validation_accuracy\n",
    "        global_best_model_state = best_model_state\n",
    "    # returning the validation loss\n",
    "    return best_validation_accuracy\n",
    "\n",
    "# Running the hyperparameter tuning with optuna\n",
    "# aim is to minimize the validation loss\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# Running 10 hyperparameter trials\n",
    "study.optimize(optimization,n_trials=10)\n",
    "\n",
    "print(\"Best Hyperparameters:\",study.best_params)\n",
    "\n",
    "\n",
    "# Saving the Best Model\n",
    "if global_best_model_state is not None:\n",
    "    torch.save(global_best_model_state, \"best_multimodal_classifier.pth\")\n",
    "    print(\"Best model saved successfully!\")\n",
    "else:\n",
    "    print(\"No best model found to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8722222222222222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_locations = len(location_encoder.classes_)\n",
    "\n",
    "best_model = RiskLevelClassifier(hidden_dim=study.best_params[\"hidden_dimension\"],n_locations=n_locations).to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(\"best_multimodal_classifier.pth\"))\n",
    "best_model.eval()\n",
    "\n",
    "test_data = DataLoader(val_set,batch_size=study.best_params[\"batch_size\"],shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "optimizers = study.best_params[\"optimizer\"]\n",
    "\n",
    "\n",
    "if optimizers ==\"Adam\":\n",
    "    optimizer = optim.Adam(best_model.parameters(),lr=study.best_params[\"learning_rate\"],weight_decay=1e-4)\n",
    "elif optimizers ==\"SGD\":\n",
    "    optimizer = optim.SGD(best_model.parameters(),lr=study.best_params[\"learning_rate\"],momentum=0.9)\n",
    "elif optimizers ==\"AdamW\":\n",
    "    optimizer = optim.AdamW(best_model.parameters(),lr=study.best_params[\"learning_rate\"],weight_decay=1e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for spectrograms, labels, locations in test_data:\n",
    "        spectrograms = spectrograms.to(device)\n",
    "        locations = locations.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = best_model(spectrograms, locations)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * spectrograms.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_accuracy = test_correct/ test_total\n",
    "    print(\"Test Accuracy:\",test_accuracy)\n",
    "\n",
    "\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"FSD50K_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>location</th>\n",
       "      <th>risk_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128802</td>\n",
       "      <td>Acoustic_guitar</td>\n",
       "      <td>Home</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8462</td>\n",
       "      <td>Acoustic_guitar</td>\n",
       "      <td>Home</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41750</td>\n",
       "      <td>Acoustic_guitar</td>\n",
       "      <td>Home</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>252380</td>\n",
       "      <td>Acoustic_guitar</td>\n",
       "      <td>Home</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18483</td>\n",
       "      <td>Acoustic_guitar</td>\n",
       "      <td>Home</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fname            label location risk_level\n",
       "0  128802  Acoustic_guitar     Home     Normal\n",
       "1    8462  Acoustic_guitar     Home     Normal\n",
       "2   41750  Acoustic_guitar     Home     Normal\n",
       "3  252380  Acoustic_guitar     Home     Normal\n",
       "4   18483  Acoustic_guitar     Home     Normal"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_explanation(label, location, risk):\n",
    "    danger_templates = [\n",
    "        f\"A {label} sound in the {location} signals a critical situation. Take action immediately.\",\n",
    "        f\"Warning: {label} noise detected at the {location}. It's classified as dangerous.\",\n",
    "        f\"Emergency alert! A {label} was heard in the {location}. Respond now.\",\n",
    "        f\"A potentially life-threatening {label} sound occurred in the {location}. Urgent attention required.\",\n",
    "        f\"The {location} is experiencing a dangerous {label} event. Please evacuate or seek shelter.\",\n",
    "        f\"Detected a hazardous {label} at the {location}. Stay away from the area.\",\n",
    "        f\"Critical: {label} identified at the {location}. Engage emergency protocols.\",\n",
    "        f\"Authorities have flagged the {label} sound at the {location} as highly dangerous.\",\n",
    "        f\"A high-risk {label} sound was reported in the {location}. Monitor the situation closely.\",\n",
    "        f\"The presence of {label} in the {location} may indicate a serious threat.\",\n",
    "        f\"A {label} was recorded in the {location}, requiring urgent investigation.\",\n",
    "        f\"Serious warning: A {label} sound was picked up in the {location}. Act fast.\",\n",
    "        f\"Immediate action advised: {label} sound from the {location} poses severe risk.\",\n",
    "        f\"A {label} sound was confirmed at the {location}, triggering an emergency response.\",\n",
    "        f\"Risk alert: Dangerous {label} sounds at the {location} demand immediate attention.\",\n",
    "    ]\n",
    "\n",
    "    threat_templates = [\n",
    "        f\"A {label} was heard at the {location}, indicating a potential threat.\",\n",
    "        f\"Sound monitoring flagged a {label} in the {location}. Stay alert.\",\n",
    "        f\"A suspicious {label} sound emerged from the {location}. Further review needed.\",\n",
    "        f\"{label} noise in the {location} may indicate unusual activity. Exercise caution.\",\n",
    "        f\"A potentially concerning {label} was picked up in the {location}.\",\n",
    "        f\"Monitor the {location} closely after detecting a {label} sound.\",\n",
    "        f\"Attention: {label} activity in the {location} may suggest a developing situation.\",\n",
    "        f\"A {label} was detected in the {location}, possibly signaling a minor threat.\",\n",
    "        f\"Advisory: {label} sounds reported from the {location}. Take precautions.\",\n",
    "        f\"The {location} registered a {label} sound that may need follow-up.\",\n",
    "        f\"A {label} sound could indicate early signs of a threat at the {location}.\",\n",
    "        f\"{label} occurrence at the {location} warrants increased observation.\",\n",
    "        f\"Initial detection of {label} in the {location} could precede an escalation.\",\n",
    "        f\"The presence of a {label} at the {location} should not be ignored.\",\n",
    "        f\"Unusual {label} activity reported in the {location}. Monitor for updates.\",\n",
    "    ]\n",
    "\n",
    "    safe_templates = [\n",
    "        f\"A {label} sound was recorded at the {location}, but it poses no threat.\",\n",
    "        f\"Routine {label} noise was detected in the {location}. No action needed.\",\n",
    "        f\"Normal acoustic activity: {label} sound observed in the {location}.\",\n",
    "        f\"The sound of {label} in the {location} is consistent with safe conditions.\",\n",
    "        f\"{label} detected in the {location} is categorized as safe.\",\n",
    "        f\"The environment at the {location} is secure despite the {label} sound.\",\n",
    "        f\"A {label} was picked up in the {location}, classified as non-threatening.\",\n",
    "        f\"Low-risk {label} activity in the {location} detected. Situation is stable.\",\n",
    "        f\"The {location} experienced a typical {label} sound event.\",\n",
    "        f\"A {label} sound is heard in the {location}, but it's nothing to worry about.\",\n",
    "        f\"Acoustic scan shows normal {label} presence in the {location}.\",\n",
    "        f\"Sound levels at the {location}, including {label}, are within safe bounds.\",\n",
    "        f\"The {label} sound in the {location} is part of usual background activity.\",\n",
    "        f\"{label} was identified in the {location}, with no associated risk.\",\n",
    "        f\"Everything is calm in the {location} despite the detection of {label}.\",\n",
    "    ]\n",
    "\n",
    "    if risk == \"Danger\":\n",
    "        return random.choice(danger_templates)\n",
    "    elif risk == \"Potential Threat\":\n",
    "        return random.choice(threat_templates)\n",
    "    else:\n",
    "        return random.choice(safe_templates)\n",
    "\n",
    "def generate_input_text(label, location, risk):\n",
    "    return f\"Audio: {label} | Location: {location} | Risk: {risk}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['input_text'] = data.apply(lambda row: generate_input_text(row['label'], row['location'], row['risk_level']), axis=1)\n",
    "data['target_text'] = data.apply(lambda row: generate_explanation(row['label'], row['location'], row['risk_level']), axis=1)\n",
    "\n",
    "# Saving the  the prepared data\n",
    "data[['input_text', 'target_text']].to_csv(\"explanation_generation_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# reading the data\n",
    "data_text = pd.read_csv(\"explanation_generation_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Audio: Acoustic_guitar | Location: Home | Risk...</td>\n",
       "      <td>Acoustic scan shows normal Acoustic_guitar pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audio: Acoustic_guitar | Location: Home | Risk...</td>\n",
       "      <td>Routine Acoustic_guitar noise was detected in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audio: Acoustic_guitar | Location: Home | Risk...</td>\n",
       "      <td>A Acoustic_guitar sound was recorded at the Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audio: Acoustic_guitar | Location: Home | Risk...</td>\n",
       "      <td>Sound levels at the Home, including Acoustic_g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Audio: Acoustic_guitar | Location: Home | Risk...</td>\n",
       "      <td>Acoustic_guitar detected in the Home is catego...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  Audio: Acoustic_guitar | Location: Home | Risk...   \n",
       "1  Audio: Acoustic_guitar | Location: Home | Risk...   \n",
       "2  Audio: Acoustic_guitar | Location: Home | Risk...   \n",
       "3  Audio: Acoustic_guitar | Location: Home | Risk...   \n",
       "4  Audio: Acoustic_guitar | Location: Home | Risk...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Acoustic scan shows normal Acoustic_guitar pre...  \n",
       "1  Routine Acoustic_guitar noise was detected in ...  \n",
       "2  A Acoustic_guitar sound was recorded at the Ho...  \n",
       "3  Sound levels at the Home, including Acoustic_g...  \n",
       "4  Acoustic_guitar detected in the Home is catego...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/8640 [00:00<?, ? examples/s]/opt/anaconda3/envs/MSDSNP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 8640/8640 [00:00<00:00, 9523.93 examples/s]\n",
      "Map: 100%|██████████| 1080/1080 [00:00<00:00, 10533.48 examples/s]\n",
      "Map: 100%|██████████| 1080/1080 [00:00<00:00, 10508.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Applying the tokenization for the data\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "import evaluate \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    inputs= tokenizer(text[\"input_text\"],max_length =128, truncation=True,padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(text[\"target_text\"],max_length =64, truncation=True,padding=\"max_length\")\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Converting the current pandas dataframe into hugging face dataset Object, the format used by the hugging face trainer and transfomer models\n",
    "dataset = Dataset.from_pandas(data_text[['input_text', 'target_text']])\n",
    "\n",
    "# splitting the data into train, validation and test sets\n",
    "\n",
    "train_data_text = dataset.select(train_idx.tolist())\n",
    "val_data_text = dataset.select(val_idx.tolist())\n",
    "test_data_text = dataset.select(test_idx.tolist())\n",
    "\n",
    "# applying the preprocess function to all the data\n",
    "preprocessed_data_train = train_data_text.map(preprocess,batched=True)\n",
    "preprocessed_data_val = val_data_text.map(preprocess,batched=True)\n",
    "preprocessed_data_test = test_data_text.map(preprocess,batched=True)\n",
    "\n",
    "# loading the BERTScore\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# function to compute the metrics \n",
    "def eval_metrics(predictions):\n",
    "    pred, labels = predictions\n",
    "    # pred is the token ID's predicted by the model\n",
    "    # If predictions are logits, use argmax (not needed if you're using generate)\n",
    "    if isinstance(pred, tuple):\n",
    "        pred = pred[0]\n",
    "        pred = torch.argmax(torch.tensor(pred), dim=-1)\n",
    "\n",
    "    # Flatten if the elements inside are still lists (e.g. shape: [batch_size, sequence_len])\n",
    "    pred = [p.tolist() if isinstance(p, torch.Tensor) else p for p in pred]\n",
    "    labels = [l.tolist() if isinstance(l, torch.Tensor) else l for l in labels]\n",
    "\n",
    "    # converting the token ID's into human readable textual format\n",
    "    pred_decoded = tokenizer.batch_decode(pred,skip_special_tokens = True)\n",
    "    labels_decoded = tokenizer.batch_decode(labels, skip_special_tokens= True)\n",
    "\n",
    "\n",
    "    results = bertscore.compute(predictions =pred_decoded, references= labels_decoded, lang=\"en\")\n",
    "\n",
    "    return {\n",
    "        \"precision\": sum(results[\"precision\"]) / len(results[\"precision\"]),\n",
    "        \"recall\": sum(results[\"recall\"]) / len(results[\"recall\"]),\n",
    "        \"f1 score\" : sum(results[\"f1\"]) / len(results[\"f1\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "# declaring the training arguments\n",
    "train_arguments =Seq2SeqTrainingArguments(\n",
    "    output_dir = \"./explanation_model\",\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    num_train_epochs = 5,\n",
    "    weight_decay = 0.01,\n",
    "    save_total_limit = 2,\n",
    "    logging_dir = \"./logs\",\n",
    "    predict_with_generate = True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Ensures no CUDA fallback\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # optional, disable memory limit (but not enough alone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device(\"mps\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader which is used to load the data in the form of batches\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def _prepare_inputs(self, inputs):\n",
    "        return {k: v.to(\"mps\") if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/ngxdgxln57gb923874j8w4rh0000gn/T/ipykernel_3773/2425297080.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `MyTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = MyTrainer(\n"
     ]
    }
   ],
   "source": [
    "# declaring the trainer\n",
    "\n",
    "small_eval_dataset = preprocessed_data_val.select(range(300))\n",
    "#small_train_dataset = preprocessed_data_train.select(range(300))\n",
    "trainer = MyTrainer(\n",
    "    model=model,\n",
    "    args = train_arguments,\n",
    "    train_dataset = preprocessed_data_train,\n",
    "    eval_dataset = small_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator  = data_collator,\n",
    "    compute_metrics = eval_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5400' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5400/5400 30:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.322900</td>\n",
       "      <td>0.207532</td>\n",
       "      <td>0.947340</td>\n",
       "      <td>0.950382</td>\n",
       "      <td>0.948835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.107456</td>\n",
       "      <td>0.972006</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.972946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.081559</td>\n",
       "      <td>0.975602</td>\n",
       "      <td>0.977326</td>\n",
       "      <td>0.976452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.071515</td>\n",
       "      <td>0.979060</td>\n",
       "      <td>0.980137</td>\n",
       "      <td>0.979589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.069098</td>\n",
       "      <td>0.979477</td>\n",
       "      <td>0.980568</td>\n",
       "      <td>0.980012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "trainer.train()\n",
    "trainer.save_model(\"./explanation_model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Wind_instrument_and_woodwind_instrument sound was recorded at the School, triggering an emergency response.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./explanation_model_final\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "input_text = \"Audio: Wind_instrument_and_woodwind_instrument | Location: School | Risk: Danger\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    max_new_tokens=60\n",
    ")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSDSNP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
